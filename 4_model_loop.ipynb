{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns \n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from datetime import date\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_perform(X_train,y_train, X_test, y_test, model, name, verbose = 0 ):\n",
    "    # train \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # test \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "    if verbose == 1 :\n",
    "        print(' MAE {} '.format(mean_absolute_error(y_pred_test,y_test)))\n",
    "        print(' MSE {} '.format(mean_squared_error(y_pred_test,y_test)))\n",
    "        print(' R2 {} '.format(r2_score(y_train,y_pred_train)))\n",
    "    else : \n",
    "        pass \n",
    "    \n",
    "    result = {}\n",
    "    result['mae'] = np.round(mean_absolute_error(y_pred_test,y_test),5)\n",
    "    result['mse'] = np.round(mean_squared_error(y_pred_test,y_test),5)\n",
    "    result['R2'] = np.round(r2_score(y_train,y_pred_train),5)\n",
    "    result['name'] = name\n",
    "    result['feature_size'] = X_train.shape[1]\n",
    "    result['train_size'] = X_train.shape[0]\n",
    "    result['test_size'] = X_test.shape[0]\n",
    "\n",
    "    return model, y_pred_test, y_pred_train, result \n",
    "\n",
    "def show_error_pattern(y_pred, y_test):\n",
    "    result_test = pd.DataFrame()\n",
    "    result_test['score'] = y_pred\n",
    "    result_test['type'] = 'predict'\n",
    "    result_test['idx'] = np.arange(result_test.shape[0])\n",
    "\n",
    "    result_test2 = pd.DataFrame()\n",
    "    result_test2['score'] = np.squeeze(y_test)\n",
    "    result_test2['type'] = 'test'\n",
    "    result_test2['idx'] = np.arange(result_test2.shape[0])\n",
    "\n",
    "    df_result = pd.concat([result_test2,result_test])\n",
    "\n",
    "    sns.lineplot(data=df_result, x=\"idx\", y='score', hue=\"type\")\n",
    "\n",
    "\n",
    "def bulk_train(df_input, drop_column, target_column, dataset_name, verbose = 0):\n",
    "\n",
    "    error_report = []\n",
    "    model_dict = {}\n",
    "\n",
    "    # scaled the values \n",
    "    features_columns = df_input.drop(drop_column,axis=1).columns\n",
    "    features_columns = list(features_columns) + [target_column]\n",
    "    scaler = MinMaxScaler()\n",
    "    df_input_scale = pd.DataFrame(scaler.fit_transform(df_input[features_columns]), columns = features_columns)\n",
    "    \n",
    "\n",
    "    # split train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_input_scale.drop(target_column, axis=1), df_input_scale[target_column], test_size=0.12, random_state=42)\n",
    "\n",
    "    regr = RandomForestRegressor(random_state=0)\n",
    "    model_regr, y_pred_test_regr, y_pred_train_regr, result_rf   = model_perform(X_train, y_train, X_test, y_test, regr, name='rf', verbose = verbose )\n",
    "    error_report.append(result_rf)\n",
    "\n",
    "    xgbr = XGBRegressor(random_state=0)\n",
    "    model_xgbr, y_pred_test_xgbr, y_pred_train_xgbr, result_xgb  = model_perform(X_train, y_train, X_test, y_test, xgbr, name='xgb', verbose = verbose)\n",
    "    error_report.append(result_xgb)\n",
    "\n",
    "    # SVR \n",
    "    svr = SVR(kernel='poly')\n",
    "    model_svr, y_pred_test_svr, y_pred_train_svr, result_svr  = model_perform(X_train, y_train, X_test, y_test, svr, name='svr',verbose = verbose)\n",
    "    error_report.append(result_svr)\n",
    "\n",
    "    model_dict['rf'] = model_regr\n",
    "    model_dict['xgbr'] = result_xgb\n",
    "    model_dict['svr'] = result_svr\n",
    "    \n",
    "    df_report = pd.DataFrame(error_report)\n",
    "    df_report['dataset'] = dataset_name\n",
    "    return  model_dict, df_report\n",
    "\n",
    "\n",
    "def bulk_train_k_fold(df_input, drop_column, target_column, dataset_name, verbose = 0):\n",
    "\n",
    "\n",
    "    # scaled the values \n",
    "    features_columns = df_input.drop(drop_column,axis=1).columns\n",
    "    features_columns = list(features_columns) + [target_column]\n",
    "    scaler = MinMaxScaler()\n",
    "    df_input_scale = pd.DataFrame(scaler.fit_transform(df_input[features_columns]), columns = features_columns)\n",
    "\n",
    "    scoring = ['neg_mean_absolute_error','neg_mean_squared_error','r2']\n",
    "\n",
    "\n",
    "    regr = RandomForestRegressor(random_state=0)\n",
    "    result_rf = cross_validation(regr, df_input_scale.drop(target_column, axis=1), df_input_scale[target_column], scoring = scoring, cv =5 )\n",
    "    df_rf = pd.DataFrame(result_rf)\n",
    "    df_rf['name'] = 'rf'\n",
    "\n",
    "    xgbr = XGBRegressor(random_state=0)\n",
    "    result_xgb = cross_validation(xgbr, df_input_scale.drop(target_column, axis=1), df_input_scale[target_column], scoring = scoring, cv =5 )\n",
    "    df_xgb = pd.DataFrame(result_xgb)\n",
    "    df_xgb['name'] = 'xgb'\n",
    "\n",
    "\n",
    "    svr = SVR(kernel='poly')\n",
    "    result_svr = cross_validation(svr, df_input_scale.drop(target_column, axis=1), df_input_scale[target_column], scoring = scoring, cv =5 )\n",
    "    df_svr = pd.DataFrame(result_svr)\n",
    "    df_svr['name'] = 'svr'\n",
    "\n",
    "    df_result = pd.concat([df_rf,df_xgb,df_svr])\n",
    "    df_result['dataset'] = dataset_name\n",
    "\n",
    "    return df_result\n",
    "\n",
    "\n",
    "def cross_validation(model, X, y, scoring, cv=5):\n",
    "\n",
    "    results = cross_validate(estimator=model,\n",
    "                               X=X,\n",
    "                               y=y,\n",
    "                               cv=cv,\n",
    "                               scoring=scoring,\n",
    "                               return_train_score=True)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zomato only\n",
    "df_zom = pd.read_csv('data/3_clean_zomato_feat.csv')\n",
    "df_zom['rest_price_idr'] = df_zom['rest_price_idr'] / 1000\n",
    "df_zom['rest_price_idr'] = df_zom['rest_price_idr'].astype(int)\n",
    "\n",
    "drop_column = ['url','index','rating','lat','long','review','new_code_res_type','new_code_fac']\n",
    "target_column = 'rating'\n",
    "\n",
    "# loop = 15 \n",
    "# list_report_zom = []\n",
    "\n",
    "# for i in range(0,15):\n",
    "#     model_zom, report_zom = bulk_train(df_input=df_zom, drop_column=drop_column, target_column=target_column, dataset_name='zomato_only')\n",
    "#     report_zom['iteration'] = i\n",
    "#     list_report_zom.append(report_zom)\n",
    "\n",
    "# df_report_zom = pd.concat(list_report_zom).reset_index()\n",
    "\n",
    "# cross validation \n",
    "\n",
    "result_zomato= bulk_train_k_fold(df_input=df_zom, drop_column=drop_column, target_column=target_column, dataset_name='zomato_only')\n",
    "result_zomato['test_neg_mean_squared_error']= result_zomato['test_neg_mean_squared_error']*-1\n",
    "result_zomato['test_neg_mean_absolute_error']= result_zomato['test_neg_mean_absolute_error']*-1\n",
    "result_zomato['feature_size'] = len(df_zom.drop(drop_column, axis=1).columns)\n",
    "result_zomato['record'] = df_zom.drop(drop_column, axis=1).shape[0]\n",
    "result_zomato = result_zomato.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zomato geo 250\n",
    "df_zom_poi = pd.read_csv('data/3_clean_zomato_gof_250.csv')\n",
    "df_zom_poi['rest_price_idr'] = df_zom_poi['rest_price_idr'] / 1000\n",
    "df_zom_poi['rest_price_idr'] = df_zom_poi['rest_price_idr'].astype(int)\n",
    "\n",
    "drop_column = ['url','index','rating','lat','long','review','new_code_res_type','new_code_fac','geohash','encode']\n",
    "target_column = 'rating'\n",
    "\n",
    "result_zomato_250 = bulk_train_k_fold(df_input=df_zom_poi, drop_column=drop_column, target_column=target_column, dataset_name='zomato_poi_250')\n",
    "result_zomato_250['test_neg_mean_squared_error'] = result_zomato_250['test_neg_mean_squared_error']*-1\n",
    "result_zomato_250['test_neg_mean_absolute_error'] = result_zomato_250['test_neg_mean_absolute_error']*-1\n",
    "result_zomato_250['feature_size'] = len(df_zom_poi.drop(drop_column, axis=1).columns)\n",
    "result_zomato_250['record'] = df_zom_poi.drop(drop_column, axis=1).shape[0]\n",
    "\n",
    "result_zomato_250 = result_zomato_250.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zomato geo 500\n",
    "df_zom_poi = pd.read_csv('data/3_clean_zomato_gof_500.csv')\n",
    "df_zom_poi['rest_price_idr'] = df_zom_poi['rest_price_idr'] / 1000\n",
    "df_zom_poi['rest_price_idr'] = df_zom_poi['rest_price_idr'].astype(int)\n",
    "\n",
    "drop_column = ['url','index','rating','lat','long','review','new_code_res_type','new_code_fac','geohash','encode']\n",
    "target_column = 'rating'\n",
    "\n",
    "result_zomato_500 = bulk_train_k_fold(df_input=df_zom_poi, drop_column=drop_column, target_column=target_column, dataset_name='zomato_poi_500')\n",
    "result_zomato_500['test_neg_mean_squared_error'] = result_zomato_500['test_neg_mean_squared_error']*-1\n",
    "result_zomato_500['test_neg_mean_absolute_error'] = result_zomato_500['test_neg_mean_absolute_error']*-1\n",
    "result_zomato_500['feature_size'] = len(df_zom_poi.drop(drop_column, axis=1).columns)\n",
    "result_zomato_500['record'] = df_zom_poi.drop(drop_column, axis=1).shape[0]\n",
    "\n",
    "result_zomato_500 = result_zomato_500.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zomato geo 1000\n",
    "df_zom_poi = pd.read_csv('data/3_clean_zomato_gof_1000.csv')\n",
    "df_zom_poi['rest_price_idr'] = df_zom_poi['rest_price_idr'] / 1000\n",
    "df_zom_poi['rest_price_idr'] = df_zom_poi['rest_price_idr'].astype(int)\n",
    "\n",
    "drop_column = ['url','index','rating','lat','long','review','new_code_res_type','new_code_fac','geohash','encode']\n",
    "target_column = 'rating'\n",
    "\n",
    "result_zomato_1000 = bulk_train_k_fold(df_input=df_zom_poi, drop_column=drop_column, target_column=target_column, dataset_name='zomato_poi_1000')\n",
    "result_zomato_1000['test_neg_mean_squared_error'] = result_zomato_1000['test_neg_mean_squared_error']*-1\n",
    "result_zomato_1000['test_neg_mean_absolute_error'] = result_zomato_1000['test_neg_mean_absolute_error']*-1\n",
    "result_zomato_1000['feature_size'] = len(df_zom_poi.drop(drop_column, axis=1).columns)\n",
    "result_zomato_1000['record'] = df_zom_poi.drop(drop_column, axis=1).shape[0]\n",
    "\n",
    "\n",
    "result_zomato_1000 = result_zomato_1000.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_zom_poi.drop(drop_column,axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_result = pd.concat([result_zomato,result_zomato_250, result_zomato_500, result_zomato_1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2022-11-11\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "print(\"Today's date:\", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_result.to_excel('data/ml_perform_crossval_{}.xlsx'.format(today),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rest_price_idr', 'is_chain', 'rank_res_type', 'rank_fac',\n",
       "       'd_1000_airport', 'd_1000_atm', 'd_1000_bank', 'd_1000_cafe',\n",
       "       'd_1000_convenience_store', 'd_1000_gas_station', 'd_1000_hospital',\n",
       "       'd_1000_lodging', 'd_1000_meal_takeaway', 'd_1000_mosque',\n",
       "       'd_1000_park', 'd_1000_restaurant', 'd_1000_school', 'd_1000_store',\n",
       "       'd_1000_supermarket', 'd_1000_train_station', 'en_1000',\n",
       "       'n_compt_1000'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zom_poi.drop(drop_column, axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column 'test_neg_mean_squarred_error' does not exist!\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1eddd7758bb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_total_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dataset'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'feature_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'test_neg_mean_absolute_error'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'std'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test_neg_mean_squarred_error'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'std'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\a.rahmadi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\a.rahmadi\\Anaconda3\\lib\\site-packages\\pandas\\core\\aggregation.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(obj, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0marg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAggFuncTypeDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0magg_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# we require a list, but not an 'str'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\a.rahmadi\\Anaconda3\\lib\\site-packages\\pandas\\core\\aggregation.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[1;34m(obj, arg, _axis)\u001b[0m\n\u001b[0;32m    744\u001b[0m                 \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m             ):\n\u001b[1;32m--> 746\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Column '{k}' does not exist!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[0marg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column 'test_neg_mean_squarred_error' does not exist!\""
     ]
    }
   ],
   "source": [
    "df_total_result.groupby(['name','dataset','feature_size']).agg({'test_neg_mean_absolute_error':['mean','std'],'test_neg_mean_squared_error':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_size</th>\n",
       "      <th>record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.908566</td>\n",
       "      <td>0.058291</td>\n",
       "      <td>0.082488</td>\n",
       "      <td>-0.040561</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>-0.002961</td>\n",
       "      <td>-0.027351</td>\n",
       "      <td>0.700022</td>\n",
       "      <td>rf</td>\n",
       "      <td>zomato_only</td>\n",
       "      <td>4</td>\n",
       "      <td>5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.782950</td>\n",
       "      <td>0.033311</td>\n",
       "      <td>0.083364</td>\n",
       "      <td>-0.040686</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>-0.050836</td>\n",
       "      <td>0.692511</td>\n",
       "      <td>rf</td>\n",
       "      <td>zomato_only</td>\n",
       "      <td>4</td>\n",
       "      <td>5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.790710</td>\n",
       "      <td>0.031301</td>\n",
       "      <td>0.077389</td>\n",
       "      <td>-0.041258</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>-0.003073</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>0.694866</td>\n",
       "      <td>rf</td>\n",
       "      <td>zomato_only</td>\n",
       "      <td>4</td>\n",
       "      <td>5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.743565</td>\n",
       "      <td>0.031360</td>\n",
       "      <td>0.076426</td>\n",
       "      <td>-0.040529</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.051732</td>\n",
       "      <td>0.708132</td>\n",
       "      <td>rf</td>\n",
       "      <td>zomato_only</td>\n",
       "      <td>4</td>\n",
       "      <td>5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.770754</td>\n",
       "      <td>0.032489</td>\n",
       "      <td>0.077335</td>\n",
       "      <td>-0.041066</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>-0.003066</td>\n",
       "      <td>-0.136452</td>\n",
       "      <td>0.701054</td>\n",
       "      <td>rf</td>\n",
       "      <td>zomato_only</td>\n",
       "      <td>4</td>\n",
       "      <td>5803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0      0  0.908566    0.058291                      0.082488   \n",
       "1      1  0.782950    0.033311                      0.083364   \n",
       "2      2  0.790710    0.031301                      0.077389   \n",
       "3      3  0.743565    0.031360                      0.076426   \n",
       "4      4  0.770754    0.032489                      0.077335   \n",
       "\n",
       "   train_neg_mean_absolute_error  test_neg_mean_squared_error  \\\n",
       "0                      -0.040561                     0.010846   \n",
       "1                      -0.040686                     0.010949   \n",
       "2                      -0.041258                     0.009845   \n",
       "3                      -0.040529                     0.009491   \n",
       "4                      -0.041066                     0.010019   \n",
       "\n",
       "   train_neg_mean_squared_error   test_r2  train_r2 name      dataset  \\\n",
       "0                     -0.002961 -0.027351  0.700022   rf  zomato_only   \n",
       "1                     -0.002995 -0.050836  0.692511   rf  zomato_only   \n",
       "2                     -0.003073  0.009837  0.694866   rf  zomato_only   \n",
       "3                     -0.002983 -0.051732  0.708132   rf  zomato_only   \n",
       "4                     -0.003066 -0.136452  0.701054   rf  zomato_only   \n",
       "\n",
       "   feature_size  record  \n",
       "0             4    5803  \n",
       "1             4    5803  \n",
       "2             4    5803  \n",
       "3             4    5803  \n",
       "4             4    5803  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9980599ad9850bdffd342280c0ae1db934122879fcb1d3c5fb59c8802b20124c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
